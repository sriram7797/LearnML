{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('C:/Users/sappusamy/Documents/SriWK/datasets/IMDB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    137\n",
       "positive    113\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    58\n",
       "positive    42\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = dataset[:100]\n",
    "train.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    79\n",
       "positive    71\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = dataset[100:].reset_index(drop=True)\n",
    "test.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP: Cleaning & Preprocessing text\n",
    "- Remove HTML\n",
    "- Tokenization + Remove punctuation\n",
    "- Remove stopwords\n",
    "- Lemmatization or stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    return BeautifulSoup(text,'lxml').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return \"\".join([c for c in text if c not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    return [w for w in text if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemmatizer(text):\n",
    "    return [lemmatizer.lemmatize(i) for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stemmer(text):\n",
    "    return [stemmer.stem(i) for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train['review'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative', 'positive'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train['sentiment']\n",
    "\n",
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_index = {'negative':0,'positive':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Represent each word in ONE-HOT encoding\n",
    "- as of now, for reducing vector length of input we set min frequency of token to be **SOME INT VALUE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_frequency(l):\n",
    "    count = {}\n",
    "    for tokens in l:\n",
    "        for token in tokens:\n",
    "            if token not in count:\n",
    "                count[token]=1\n",
    "            else:\n",
    "                count[token]+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = token_frequency(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movi', 209),\n",
       " ('film', 156),\n",
       " ('one', 104),\n",
       " ('like', 84),\n",
       " ('see', 59),\n",
       " ('even', 59),\n",
       " ('get', 58),\n",
       " ('good', 56),\n",
       " ('scene', 55),\n",
       " ('go', 54)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(tf.items(),key=lambda x:x[1],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(tf):\n",
    "    v = {}\n",
    "    v['pad']=0\n",
    "    v['unk']=1\n",
    "    for token in tf:\n",
    "        if tf[token]>=min_freq:\n",
    "            v[token] = len(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocabulary(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1665"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's convert tokens to index and make vector for each word in a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['one',\n",
       "  'review',\n",
       "  'mention',\n",
       "  'watch',\n",
       "  '1',\n",
       "  'oz',\n",
       "  'episod',\n",
       "  'youll',\n",
       "  'hook',\n",
       "  'right'],\n",
       " 168)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = t[0]\n",
    "tokens[:10],len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [vocab[token] if token in vocab else vocab['unk'] for token in tokens]\n",
    "len(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's convert these indices to one-hot vectors\n",
    "- shape of input will be sequence_length * vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(len(indices),len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[range(len(indices)),indices]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]), torch.Size([168, 1665]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation of RNN:\n",
    "\\begin{equation*}\n",
    "h_t = tanh( W_{ih}X_t + b_{ih} + W_{hh}h_{t-1} + b_{hh})\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell = nn.RNNCell(len(vocab),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih torch.Size([100, 1665])\n",
      "weight_hh torch.Size([100, 100])\n",
      "bias_ih torch.Size([100])\n",
      "bias_hh torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for name,p in rnn_cell.named_parameters():\n",
    "    print(name,p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    h = rnn_cell(x[i].view(1,-1),h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**value of hidden vector after iterating over all input time steps**\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0338,  0.2030, -0.0317,  0.1212, -0.0954,  0.2023, -0.0252,  0.1759,\n",
       "          0.0280, -0.0647, -0.1002, -0.2748,  0.1378, -0.1062, -0.0938,  0.1268,\n",
       "          0.0855, -0.0884, -0.0353,  0.1125, -0.1529, -0.0224, -0.0970,  0.0887,\n",
       "         -0.1953,  0.2198, -0.1126, -0.1194, -0.0228,  0.0083,  0.0334,  0.0451,\n",
       "          0.2578, -0.0333,  0.0253, -0.1298, -0.1032,  0.0850,  0.0416,  0.2748,\n",
       "         -0.1233, -0.1222,  0.1226, -0.0876,  0.0214,  0.1448,  0.0715, -0.1146,\n",
       "         -0.0933,  0.0641, -0.1560,  0.0219,  0.0711,  0.1127,  0.0399,  0.2929,\n",
       "          0.1157,  0.1337, -0.0430,  0.0921, -0.0098,  0.1768,  0.0964,  0.1148,\n",
       "          0.1065,  0.1152, -0.0201, -0.1322,  0.0811, -0.0056,  0.0863, -0.1216,\n",
       "         -0.0200, -0.0467,  0.0941,  0.0971, -0.0695, -0.0328, -0.1126,  0.0755,\n",
       "         -0.1399,  0.1264,  0.0886, -0.0006,  0.1397, -0.0786,  0.0053, -0.0732,\n",
       "          0.2332, -0.0433,  0.1511, -0.0179, -0.1454,  0.0597,  0.1681,  0.0844,\n",
       "          0.1815,  0.1823, -0.0294,  0.1212]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"**value of hidden vector after iterating over all input time steps**\")\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In RNNCell,\n",
    "    \n",
    "    inputs are looped over each time steps\n",
    "\n",
    "<a href=\"https://pytorch.org/docs/stable/nn.html?highlight=rnncell#torch.nn.RNNCell\">PyTorch RNNCell reference</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN for 1 training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(len(vocab),100,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [vocab[token] if token in vocab else vocab['unk'] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(len(indices),len(vocab))\n",
    "\n",
    "x[range(len(indices)),indices]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]), torch.Size([1, 168, 1665]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.expand((1,-1,len(vocab)))\n",
    "x,x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shape of h:-**\n",
    "    \n",
    "    h = (num_layers*num_directions, bacth_size, hidden_units)\n",
    "    \n",
    "    where num_layers parameter take int value as inputs which build ups STACKED RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros(1,1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output,hidden = rnn(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 168, 100]), torch.Size([1, 1, 100]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape,hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**output** - output of all time steps of all batches\n",
    "\n",
    "**hidden** - output of last time step of all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Linear(100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1914,  0.1241]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = classifier(hidden.view(1,100))\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN for m training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([{'params':rnn.parameters()},{'params':classifier.parameters()}],lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5478092432022095\n",
      "0.6081416606903076\n",
      "0.5728379487991333\n",
      "0.7896133065223694\n",
      "0.57362961769104\n",
      "0.5618698596954346\n",
      "0.5614193081855774\n",
      "0.949131965637207\n",
      "0.9032877683639526\n",
      "0.5481340885162354\n",
      "0.8621177673339844\n",
      "0.8069772720336914\n",
      "0.8193782567977905\n",
      "0.7865504026412964\n",
      "0.6081416606903076\n",
      "0.7942619323730469\n",
      "0.6361009478569031\n",
      "0.7926075458526611\n",
      "0.581184446811676\n",
      "0.7988814115524292\n",
      "0.6344434022903442\n",
      "0.8012036085128784\n",
      "0.5854486227035522\n",
      "0.7781751751899719\n",
      "0.777474045753479\n",
      "0.6703867316246033\n",
      "0.6205466985702515\n",
      "0.7958093881607056\n",
      "0.7427211403846741\n",
      "0.6948776841163635\n",
      "0.6429101824760437\n",
      "0.6244244575500488\n",
      "0.8053395748138428\n",
      "0.6195626258850098\n",
      "0.7716079354286194\n",
      "0.7250599265098572\n",
      "0.7328423261642456\n",
      "0.7341915369033813\n",
      "0.6754580736160278\n",
      "0.7119659781455994\n",
      "0.6926265954971313\n",
      "0.6940498352050781\n",
      "0.6971608400344849\n",
      "0.6652841567993164\n",
      "0.7352091073989868\n",
      "0.7601959109306335\n",
      "0.6388621926307678\n",
      "0.6862215399742126\n",
      "0.7318757772445679\n",
      "0.690115749835968\n",
      "0.7886290550231934\n",
      "0.6736520528793335\n",
      "0.691016674041748\n",
      "0.6656542420387268\n",
      "0.7175949215888977\n",
      "0.7111822366714478\n",
      "0.7024388909339905\n",
      "0.6769353747367859\n",
      "0.7621180415153503\n",
      "0.6966201066970825\n",
      "0.7054659128189087\n",
      "0.6957997679710388\n",
      "0.7559858560562134\n",
      "0.6595281362533569\n",
      "0.6942291855812073\n",
      "0.752166211605072\n",
      "0.6865498423576355\n",
      "0.6644390821456909\n",
      "0.6045379042625427\n",
      "0.6115585565567017\n",
      "0.573861300945282\n",
      "0.5549161434173584\n",
      "0.8308436870574951\n",
      "0.8266646862030029\n",
      "0.6285359859466553\n",
      "0.8053580522537231\n",
      "0.811347484588623\n",
      "0.5886178016662598\n",
      "0.6261656284332275\n",
      "0.8393756151199341\n",
      "0.776353120803833\n",
      "0.6589534878730774\n",
      "0.5941135883331299\n",
      "0.578338623046875\n",
      "0.6188538670539856\n",
      "0.5697560906410217\n",
      "0.5185896158218384\n",
      "0.545619010925293\n",
      "0.5252339243888855\n",
      "0.4956585168838501\n",
      "0.9998692870140076\n",
      "0.5396628379821777\n",
      "0.9385782480239868\n",
      "0.857419490814209\n",
      "0.5160152316093445\n",
      "0.892813503742218\n",
      "0.5803612470626831\n",
      "0.5525681376457214\n",
      "0.5169515013694763\n",
      "0.9436558485031128\n"
     ]
    }
   ],
   "source": [
    "for doc,y in zip(indices,labels):\n",
    "    x = torch.zeros(len(doc),len(vocab))\n",
    "    x[range(len(doc)),doc]=1\n",
    "    x = x.expand((1,-1,len(vocab)))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    h = torch.zeros(1,1,100)\n",
    "    output,hidden = rnn(x,h)\n",
    "    preds = classifier(hidden.view(1,100))\n",
    "    \n",
    "    loss = crit(preds,torch.LongTensor([labels_index[y]]))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    print(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why loop over each document?**\n",
    "\n",
    "    different documents are of differnt lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch-wise processing\n",
    "\n",
    "**Why do we need padding?**\n",
    "- sequence length of different documents will be of different length\n",
    "- so flow will be as follows:<br>\n",
    "      for doc in documents:\n",
    "          for token in doc:\n",
    "              pass to RNNCell\n",
    "- the above methods has huge complexity\n",
    "- in order to process in batch-wise, we make all documents length to be of same length\n",
    "\n",
    "    \n",
    "    Thus padding comes in, which means pads 0's to documents which has length less than max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths = [len(d) for d in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros(len(indices),max_length,len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 372, 1665])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    X[[i],range(len(indices[i])),indices[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.LongTensor([labels_index[i] for i in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(len(vocab),100,batch_first=True)\n",
    "        self.classifier = nn.Linear(100,2)\n",
    "        \n",
    "    def forward(self,x,h):\n",
    "        output,hidden = self.rnn(x,h)\n",
    "        return self.classifier(hidden.view(-1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6945303082466125\n",
      "0.6886752843856812\n",
      "0.7156445980072021\n",
      "0.6933744549751282\n",
      "0.6893102526664734\n",
      "0.6728619337081909\n",
      "0.6406792998313904\n",
      "0.7126068472862244\n",
      "0.7243829369544983\n",
      "0.6600400805473328\n",
      "0.7046942114830017\n",
      "0.6701604723930359\n",
      "0.6487911343574524\n",
      "0.614656925201416\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    for i in range(0,X.shape[0],bs):\n",
    "        xb = X[i:i+bs]\n",
    "        yb = Y[i:i+bs]\n",
    "        h = torch.zeros(1,xb.shape[0],100)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb,h)\n",
    "        loss = crit(preds,yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test['review'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "TY = torch.LongTensor([labels_index[i] for i in test.sentiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for index_num in range(len(test)):\n",
    "\n",
    "    T = torch.zeros(len(indices[index_num]),len(vocab))\n",
    "    T[range(len(indices[index_num])),indices[index_num]]=1\n",
    "    T = T.expand((1,-1,len(vocab)))\n",
    "\n",
    "    h = torch.zeros(1,T.shape[0],100)\n",
    "    with torch.no_grad():\n",
    "        predictions.append(F.softmax(model(T,h)).argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.LongTensor(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy:', tensor(0.5267))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Accuracy:\",(predictions==TY).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Number of positives predicted', tensor(0))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Number of positives predicted\",(predictions==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Number of negatives predicted', tensor(150))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Number of negatives predicted\",(predictions==0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train['review'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    if len(indices[i])<max_length:\n",
    "        indices[i]+=[0]*(max_length-len(indices[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 372])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.LongTensor(indices)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.LongTensor([labels_index[i] for i in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(len(vocab),200,padding_idx=0)\n",
    "        self.rnn = nn.RNN(200,100,batch_first=True)\n",
    "        self.classifier = nn.Linear(100,2)\n",
    "        \n",
    "    def forward(self,x,h):\n",
    "        x = self.emb(x)\n",
    "        output,hidden = self.rnn(x,h)\n",
    "        return self.classifier(hidden.view(-1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6932849287986755\n",
      "0.6955429911613464\n",
      "0.6845163106918335\n",
      "0.6550172567367554\n",
      "0.7173296809196472\n",
      "0.6731282472610474\n",
      "0.6598580479621887\n",
      "0.6215626001358032\n",
      "0.7384545803070068\n",
      "0.6664385795593262\n",
      "0.6526764035224915\n",
      "0.6095917224884033\n",
      "0.7493111491203308\n",
      "0.6631247997283936\n",
      "0.6503868103027344\n",
      "0.6052871942520142\n",
      "0.7536835670471191\n",
      "0.660831093788147\n",
      "0.649570643901825\n",
      "0.6036905646324158\n",
      "0.7552337050437927\n",
      "0.6590689420700073\n",
      "0.6492340564727783\n",
      "0.6030513048171997\n",
      "0.7557085752487183\n",
      "0.6576700210571289\n",
      "0.6490649580955505\n",
      "0.6027580499649048\n",
      "0.7557860016822815\n",
      "0.6565379500389099\n",
      "0.6489587426185608\n",
      "0.6025956273078918\n",
      "0.7557146549224854\n",
      "0.6556075215339661\n",
      "0.6488786935806274\n",
      "0.6024868488311768\n",
      "0.7555860877037048\n",
      "0.6548316478729248\n",
      "0.6488115787506104\n",
      "0.6024026870727539\n"
     ]
    }
   ],
   "source": [
    "model = Sentiment()\n",
    "\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "bs=32\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i in range(0,X.shape[0],bs):\n",
    "        xb = X[i:i+bs]\n",
    "        yb = Y[i:i+bs]\n",
    "        h = torch.zeros(1,xb.shape[0],100)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb,h)\n",
    "        loss = crit(preds,yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test['review'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]\n",
    "\n",
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "TY = torch.LongTensor([labels_index[i] for i in test.sentiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for index_num in range(len(test)):\n",
    "    T = torch.LongTensor([indices[index_num]])\n",
    "    h = torch.zeros(1,T.shape[0],100)\n",
    "    with torch.no_grad():\n",
    "        predictions.append(F.softmax(model(T,h)).argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.LongTensor(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4667)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions==TY).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 62, 17, 62)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = ((TY==1)*(predictions==1)).sum().item()\n",
    "\n",
    "tn = ((TY==0)*(predictions==0)).sum().item()\n",
    "\n",
    "fn = ((TY==1)*(predictions==0)).sum().item()\n",
    "\n",
    "fp = ((TY==0)*(predictions==1)).sum().item()\n",
    "tp,tn,fp,tn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postive label - measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.32\n",
      "Recall: 0.11267605633802817\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",tp/(tp+fp))\n",
    "\n",
    "print(\"Recall:\",tp/(tp+fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative label - measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.496\n",
      "Recall: 0.7848101265822784\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",tn/(tn+fn))\n",
    "\n",
    "print(\"Recall:\",tn/(tn+fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0033,  0.0016,  0.0011,  ..., -0.0022, -0.0021, -0.0020],\n",
       "        [-0.0022,  0.0011,  0.0007,  ..., -0.0015, -0.0014, -0.0014],\n",
       "        [-0.0035,  0.0017,  0.0012,  ..., -0.0023, -0.0022, -0.0021],\n",
       "        ...,\n",
       "        [-0.0015,  0.0007,  0.0005,  ..., -0.0010, -0.0010, -0.0009],\n",
       "        [-0.0033,  0.0016,  0.0011,  ..., -0.0021, -0.0021, -0.0020],\n",
       "        [-0.0033,  0.0016,  0.0011,  ..., -0.0021, -0.0021, -0.0020]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rnn.weight_hh_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4314e-27,  1.1330e-26, -1.0523e-27,  ..., -3.9030e-27,\n",
       "          4.9431e-27,  7.4282e-27],\n",
       "        [ 1.6336e-28,  4.5620e-26,  1.2111e-27,  ..., -1.0547e-26,\n",
       "          2.3158e-26,  2.1793e-26],\n",
       "        [ 9.2576e-27, -6.4853e-26,  7.7108e-27,  ...,  2.0990e-26,\n",
       "         -3.0852e-26, -3.7548e-26],\n",
       "        ...,\n",
       "        [-3.6814e-27,  2.6545e-26,  2.3781e-27,  ..., -7.2364e-27,\n",
       "          1.2195e-26,  1.6021e-26],\n",
       "        [ 1.4002e-27,  1.3441e-26,  3.6188e-27,  ..., -1.6093e-27,\n",
       "          6.2430e-27,  6.5735e-27],\n",
       "        [ 3.3216e-27, -1.2877e-26, -1.6718e-27,  ...,  4.1407e-27,\n",
       "         -6.0222e-27, -8.4487e-27]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rnn.weight_ih_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
