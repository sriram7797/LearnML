{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('C:/Users/sappusamy/Documents/SriWK/datasets/SPAM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Message'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = dataset[dataset.Category=='ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = dataset[dataset.Category=='spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ham[:50]\n",
    "train = train.append(spam[:50])\n",
    "train = train.sample(frac=1,random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ham[50:100]\n",
    "test = test.append(spam[50:100])\n",
    "test = test.sample(frac=1,random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP: Cleaning & Preprocessing text\n",
    "- Remove HTML\n",
    "- Tokenization + Remove punctuation\n",
    "- Remove stopwords\n",
    "- Lemmatization or stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train.Message[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    return BeautifulSoup(text,'lxml').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return \"\".join([c for c in text if c not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    return [w for w in text if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemmatizer(text):\n",
    "    return [lemmatizer.lemmatize(i) for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stemmer(text):\n",
    "    return [stemmer.stem(i) for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train['Message'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ham', 'spam'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train['Category']\n",
    "\n",
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_index = {'ham':0,'spam':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Represent each word in ONE-HOT encoding\n",
    "- as of now, for reducing vector length of input we set min frequency of token to be **SOME INT VALUE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_frequency(l):\n",
    "    count = {}\n",
    "    for tokens in l:\n",
    "        for token in tokens:\n",
    "            if token not in count:\n",
    "                count[token]=1\n",
    "            else:\n",
    "                count[token]+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = token_frequency(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('u', 23),\n",
       " ('call', 21),\n",
       " ('2', 17),\n",
       " ('go', 16),\n",
       " ('free', 16),\n",
       " ('ur', 14),\n",
       " ('mobil', 13),\n",
       " ('text', 12),\n",
       " ('txt', 11),\n",
       " ('claim', 11)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(tf.items(),key=lambda x:x[1],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(tf):\n",
    "    v = {}\n",
    "    v['pad']=0\n",
    "    v['unk']=1\n",
    "    for token in tf:\n",
    "        if tf[token]>=min_freq:\n",
    "            v[token] = len(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocabulary(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's convert tokens to index and make vector for each word in a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['500',\n",
       "  'new',\n",
       "  'mobil',\n",
       "  '2004',\n",
       "  'must',\n",
       "  'go',\n",
       "  'txt',\n",
       "  'nokia',\n",
       "  '89545',\n",
       "  'collect'],\n",
       " 15)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = t[0]\n",
    "tokens[:10],len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [vocab[token] if token in vocab else vocab['unk'] for token in tokens]\n",
    "len(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's convert these indices to one-hot vectors\n",
    "- shape of input will be sequence_length * vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(len(indices),len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[range(len(indices)),indices]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]), torch.Size([15, 749]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation of RNN:\n",
    "\\begin{equation*}\n",
    "h_t = tanh( W_{ih}X_t + b_{ih} + W_{hh}h_{t-1} + b_{hh})\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell = nn.RNNCell(len(vocab),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih torch.Size([100, 749])\n",
      "weight_hh torch.Size([100, 100])\n",
      "bias_ih torch.Size([100])\n",
      "bias_hh torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for name,p in rnn_cell.named_parameters():\n",
    "    print(name,p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    h = rnn_cell(x[i].view(1,-1),h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**value of hidden vector after iterating over all input time steps**\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-4.4142e-02,  9.4197e-02, -1.6878e-01,  2.6354e-01, -1.3140e-01,\n",
       "         -1.4577e-02, -1.4490e-02,  3.5777e-02,  2.0831e-01, -1.4552e-01,\n",
       "          9.4687e-02, -7.8661e-02, -7.1842e-02,  3.2611e-02, -2.0414e-01,\n",
       "          1.8936e-02,  1.5348e-01,  9.2606e-03, -8.3286e-02, -6.1743e-02,\n",
       "         -9.1368e-03,  1.8880e-01, -7.9705e-02,  2.1991e-01,  1.6692e-01,\n",
       "          1.0081e-01,  2.4821e-02, -1.1609e-01, -1.7894e-01, -1.9801e-02,\n",
       "         -4.5523e-01,  1.4640e-01,  1.5998e-01, -1.4366e-02,  1.9816e-01,\n",
       "         -1.2855e-01, -6.1894e-02,  1.4198e-01, -3.9010e-02,  2.3670e-01,\n",
       "          5.8060e-02,  1.4338e-01, -2.4463e-02, -1.0425e-01,  2.8902e-02,\n",
       "          8.1776e-02,  1.4509e-01,  1.9462e-01, -5.3610e-02, -6.8339e-02,\n",
       "          3.9568e-02, -1.8148e-02, -5.5171e-02, -1.2315e-02, -1.8912e-01,\n",
       "          1.4017e-01, -2.3654e-01,  1.2702e-01,  8.6424e-02,  1.0395e-01,\n",
       "         -9.0624e-02, -7.0265e-02, -6.5712e-02, -1.3446e-01, -1.1549e-01,\n",
       "          2.5833e-01,  9.5647e-02, -6.9238e-02,  3.4432e-02,  1.7855e-01,\n",
       "          1.0372e-01, -6.8134e-02,  5.1226e-02,  1.7692e-02, -9.1904e-02,\n",
       "          1.5804e-01, -3.8111e-02,  1.4761e-01, -8.4617e-02, -2.0068e-01,\n",
       "         -8.6833e-02,  6.1312e-02,  1.8256e-01,  1.7576e-01, -9.2487e-02,\n",
       "         -9.0997e-02,  9.5345e-02, -3.3690e-03, -3.6726e-02, -3.0717e-02,\n",
       "          1.0575e-01, -4.4507e-04, -9.9250e-02, -1.6069e-01,  7.3980e-02,\n",
       "         -1.4203e-01, -1.4169e-01, -1.0778e-01, -2.3150e-02, -6.7064e-02]],\n",
       "       grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"**value of hidden vector after iterating over all input time steps**\")\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In RNNCell,\n",
    "    \n",
    "    inputs are looped over each time steps\n",
    "\n",
    "<a href=\"https://pytorch.org/docs/stable/nn.html?highlight=rnncell#torch.nn.RNNCell\">PyTorch RNNCell reference</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN for 1 training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(len(vocab),100,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [vocab[token] if token in vocab else vocab['unk'] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(len(indices),len(vocab))\n",
    "\n",
    "x[range(len(indices)),indices]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]), torch.Size([1, 15, 749]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.expand((1,-1,len(vocab)))\n",
    "x,x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shape of h:-**\n",
    "    \n",
    "    h = (num_layers*num_directions, bacth_size, hidden_units)\n",
    "    \n",
    "    where num_layers parameter take int value as inputs which build ups STACKED RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros(1,1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "output,hidden = rnn(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 15, 100]), torch.Size([1, 1, 100]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape,hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**output** - output of all time steps of all batches\n",
    "\n",
    "**hidden** - output of last time step of all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Linear(100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0198,  0.0784]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = classifier(hidden.view(1,100))\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN for m training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([{'params':rnn.parameters()},{'params':classifier.parameters()}],lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6452575325965881\n",
      "0.6073843240737915\n",
      "0.5250005125999451\n",
      "0.8167086839675903\n",
      "0.8078009486198425\n",
      "0.7634955644607544\n",
      "0.7709652781486511\n",
      "0.6961570978164673\n",
      "0.7559258937835693\n",
      "0.7491001486778259\n",
      "0.6903864145278931\n",
      "0.7111412286758423\n",
      "0.7321428656578064\n",
      "0.6743751168251038\n",
      "0.7143977880477905\n",
      "0.6818093061447144\n",
      "0.7547265291213989\n",
      "0.6565196514129639\n",
      "0.7174919247627258\n",
      "0.7241765260696411\n",
      "0.7170804738998413\n",
      "0.668822169303894\n",
      "0.7855167984962463\n",
      "0.7120293378829956\n",
      "0.7420763969421387\n",
      "0.6734651327133179\n",
      "0.6923825144767761\n",
      "0.6842448115348816\n",
      "0.6697331070899963\n",
      "0.7355749011039734\n",
      "0.6599501967430115\n",
      "0.6665076613426208\n",
      "0.7174286842346191\n",
      "0.6172147989273071\n",
      "0.731817901134491\n",
      "0.6726245284080505\n",
      "0.6945776343345642\n",
      "0.7054689526557922\n",
      "0.682533860206604\n",
      "0.6886274814605713\n",
      "0.6347139477729797\n",
      "0.61833655834198\n",
      "0.6650079488754272\n",
      "0.8082593679428101\n",
      "0.6154588460922241\n",
      "0.5872073769569397\n",
      "0.7802671790122986\n",
      "0.613354504108429\n",
      "0.8168739676475525\n",
      "0.6534721851348877\n",
      "0.6413669586181641\n",
      "0.6010854840278625\n",
      "0.5520371794700623\n",
      "0.5771853923797607\n",
      "0.5302530527114868\n",
      "0.8632271885871887\n",
      "0.5353909134864807\n",
      "0.8222928047180176\n",
      "0.5839388370513916\n",
      "0.8720579743385315\n",
      "0.8488165140151978\n",
      "0.8176696300506592\n",
      "0.7604900598526001\n",
      "0.5961835980415344\n",
      "0.7446784377098083\n",
      "0.682037353515625\n",
      "0.6597847938537598\n",
      "0.7490378022193909\n",
      "0.7569723129272461\n",
      "0.7174926400184631\n",
      "0.7475653886795044\n",
      "0.6728537678718567\n",
      "0.7362703680992126\n",
      "0.6659103035926819\n",
      "0.7115722894668579\n",
      "0.6233195662498474\n",
      "0.6278810501098633\n",
      "0.7402359247207642\n",
      "0.7163122892379761\n",
      "0.6346906423568726\n",
      "0.6812702417373657\n",
      "0.5968946814537048\n",
      "0.7874518632888794\n",
      "0.7531535625457764\n",
      "0.737291693687439\n",
      "0.6984714269638062\n",
      "0.6945540904998779\n",
      "0.7504481077194214\n",
      "0.6770586967468262\n",
      "0.7087807655334473\n",
      "0.706200361251831\n",
      "0.6088044047355652\n",
      "0.6317428946495056\n",
      "0.6227990984916687\n",
      "0.8345755934715271\n",
      "0.6505072712898254\n",
      "0.6049149036407471\n",
      "0.7827637791633606\n",
      "0.6110295057296753\n",
      "0.5805668234825134\n"
     ]
    }
   ],
   "source": [
    "for doc,y in zip(indices,labels):\n",
    "    x = torch.zeros(len(doc),len(vocab))\n",
    "    x[range(len(doc)),doc]=1\n",
    "    x = x.expand((1,-1,len(vocab)))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    h = torch.zeros(1,1,100)\n",
    "    output,hidden = rnn(x,h)\n",
    "    preds = classifier(hidden.view(1,100))\n",
    "    \n",
    "    loss = crit(preds,torch.LongTensor([labels_index[y]]))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    print(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why loop over each document?**\n",
    "\n",
    "    different documents are of differnt lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch-wise processing\n",
    "\n",
    "**Why do we need padding?**\n",
    "- sequence length of different documents will be of different length\n",
    "- so flow will be as follows:<br>\n",
    "      for doc in documents:\n",
    "          for token in doc:\n",
    "              pass to RNNCell\n",
    "- the above methods has huge complexity\n",
    "- in order to process in batch-wise, we make all documents length to be of same length\n",
    "\n",
    "    \n",
    "    Thus padding comes in, which means pads 0's to documents which has length less than max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths = [len(d) for d in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros(len(indices),max_length,len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 26, 749])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    X[[i],range(len(indices[i])),indices[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.LongTensor([labels_index[i] for i in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(len(vocab),100,batch_first=True)\n",
    "        self.classifier = nn.Linear(100,2)\n",
    "        \n",
    "    def forward(self,x,h):\n",
    "        output,hidden = self.rnn(x,h)\n",
    "        return self.classifier(hidden.view(-1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7189193367958069\n",
      "0.6982823610305786\n",
      "0.695207953453064\n",
      "0.6919353604316711\n",
      "0.7174856662750244\n",
      "0.6895442605018616\n",
      "0.6674919128417969\n",
      "0.7306748628616333\n",
      "0.7034782767295837\n",
      "0.7022602558135986\n",
      "0.6942461133003235\n",
      "0.7063891291618347\n",
      "0.6883792281150818\n",
      "0.6624077558517456\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    for i in range(0,X.shape[0],bs):\n",
    "        xb = X[i:i+bs]\n",
    "        yb = Y[i:i+bs]\n",
    "        h = torch.zeros(1,xb.shape[0],100)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb,h)\n",
    "        loss = crit(preds,yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test['Message'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "TY = torch.LongTensor([labels_index[i] for i in test.Category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for index_num in range(len(test)):\n",
    "\n",
    "    T = torch.zeros(len(indices[index_num]),len(vocab))\n",
    "    T[range(len(indices[index_num])),indices[index_num]]=1\n",
    "    T = T.expand((1,-1,len(vocab)))\n",
    "\n",
    "    h = torch.zeros(1,T.shape[0],100)\n",
    "    with torch.no_grad():\n",
    "        predictions.append(F.softmax(model(T,h)).argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.LongTensor(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy:', tensor(0.5000))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Accuracy:\",(predictions==TY).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Number of positives predicted', tensor(100))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Number of positives predicted\",(predictions==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Number of negatives predicted', tensor(0))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Number of negatives predicted\",(predictions==0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train['Message'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    if len(indices[i])<max_length:\n",
    "        indices[i]+=[0]*(max_length-len(indices[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 26])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.LongTensor(indices)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.LongTensor([labels_index[i] for i in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(len(vocab),200,padding_idx=0)\n",
    "        self.rnn = nn.RNN(200,100,batch_first=True)\n",
    "        self.classifier = nn.Linear(100,2)\n",
    "        \n",
    "    def forward(self,x,h):\n",
    "        x = self.emb(x)\n",
    "        output,hidden = self.rnn(x,h)\n",
    "        return self.classifier(hidden.view(-1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6892282366752625\n",
      "0.6740912795066833\n",
      "0.7422855496406555\n",
      "0.7331304550170898\n",
      "0.701262354850769\n",
      "0.6843129396438599\n",
      "0.7027245163917542\n",
      "0.6879247426986694\n",
      "0.7143274545669556\n",
      "0.6926295757293701\n",
      "0.6863281726837158\n",
      "0.6673398017883301\n",
      "0.7220810651779175\n",
      "0.6965189576148987\n",
      "0.6788063645362854\n",
      "0.6574094295501709\n",
      "0.7253758907318115\n",
      "0.697486400604248\n",
      "0.6749976277351379\n",
      "0.6522319912910461\n",
      "0.7261216640472412\n",
      "0.6970082521438599\n",
      "0.6728103756904602\n",
      "0.6491697430610657\n",
      "0.7256330847740173\n",
      "0.6959238648414612\n",
      "0.6713466048240662\n",
      "0.6470130681991577\n",
      "0.7245992422103882\n",
      "0.6946271061897278\n",
      "0.6702021956443787\n",
      "0.6451825499534607\n",
      "0.7233366966247559\n",
      "0.6932797431945801\n",
      "0.6691867709159851\n",
      "0.6433745622634888\n",
      "0.7219727635383606\n",
      "0.6919354796409607\n",
      "0.6682024598121643\n",
      "0.641399085521698\n"
     ]
    }
   ],
   "source": [
    "model = Sentiment()\n",
    "\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "bs=32\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i in range(0,X.shape[0],bs):\n",
    "        xb = X[i:i+bs]\n",
    "        yb = Y[i:i+bs]\n",
    "        h = torch.zeros(1,xb.shape[0],100)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb,h)\n",
    "        loss = crit(preds,yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test['Message'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]\n",
    "\n",
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "TY = torch.LongTensor([labels_index[i] for i in test.Category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for index_num in range(len(test)):\n",
    "    T = torch.LongTensor([indices[index_num]])\n",
    "    h = torch.zeros(1,T.shape[0],100)\n",
    "    with torch.no_grad():\n",
    "        predictions.append(F.softmax(model(T,h)).argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.LongTensor(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6200)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions==TY).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 22, 28, 22)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = ((TY==1)*(predictions==1)).sum().item()\n",
    "\n",
    "tn = ((TY==0)*(predictions==0)).sum().item()\n",
    "\n",
    "fn = ((TY==1)*(predictions==0)).sum().item()\n",
    "\n",
    "fp = ((TY==0)*(predictions==1)).sum().item()\n",
    "tp,tn,fp,tn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postive label - measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5882352941176471\n",
      "Recall: 0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",tp/(tp+fp))\n",
    "\n",
    "print(\"Recall:\",tp/(tp+fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative label - measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6875\n",
      "Recall: 0.44\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",tn/(tn+fn))\n",
    "\n",
    "print(\"Recall:\",tn/(tn+fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.6326e-03,  1.5805e-03, -1.4267e-03,  ...,  8.2292e-04,\n",
       "          1.9990e-04, -1.5737e-03],\n",
       "        [-6.7638e-03, -6.2903e-03,  4.6110e-03,  ..., -4.1842e-03,\n",
       "          3.7333e-04,  5.3610e-03],\n",
       "        [-4.1368e-03, -3.2653e-03,  5.4916e-03,  ..., -1.7893e-03,\n",
       "         -2.3519e-03,  1.1520e-03],\n",
       "        ...,\n",
       "        [-3.7088e-03, -1.7957e-03,  3.3921e-04,  ..., -4.3912e-03,\n",
       "          1.9419e-04,  3.0356e-03],\n",
       "        [ 1.9071e-03,  1.0396e-03, -3.5588e-04,  ...,  8.1504e-04,\n",
       "         -3.8207e-04, -1.1678e-03],\n",
       "        [-9.9614e-04, -8.3925e-04,  5.0913e-04,  ...,  1.4241e-04,\n",
       "          2.8769e-06,  4.0479e-04]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rnn.weight_hh_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.4073e-04,  1.8684e-04,  1.5433e-04,  ...,  2.6987e-04,\n",
       "          7.6458e-04,  1.3815e-04],\n",
       "        [ 4.5654e-04, -3.4279e-04, -4.9347e-05,  ..., -2.4360e-04,\n",
       "         -4.8947e-04,  1.4968e-04],\n",
       "        [-5.1119e-05, -3.0856e-04,  9.5631e-04,  ..., -2.2593e-04,\n",
       "          8.7920e-04,  6.2837e-04],\n",
       "        ...,\n",
       "        [ 6.5464e-04, -4.3197e-04, -2.6080e-04,  ..., -2.6342e-04,\n",
       "         -8.8494e-04,  2.9544e-05],\n",
       "        [-2.3705e-04,  2.8603e-04,  2.5581e-04,  ...,  3.4914e-05,\n",
       "          5.2554e-04, -4.6989e-05],\n",
       "        [ 9.4197e-05,  1.0290e-04, -3.7651e-04,  ...,  8.6780e-05,\n",
       "         -6.4274e-04, -3.7865e-04]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rnn.weight_ih_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
