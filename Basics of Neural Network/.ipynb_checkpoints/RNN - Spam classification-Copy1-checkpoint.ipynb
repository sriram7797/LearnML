{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('C:/Users/sappusamy/Documents/SriWK/datasets/SPAM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Message'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = dataset[dataset.Category=='ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = dataset[dataset.Category=='spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ham[:50]\n",
    "train = train.append(spam[:50])\n",
    "train = train.sample(frac=1,random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ham[50:100]\n",
    "test = test.append(spam[50:100])\n",
    "test = test.sample(frac=1,random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP: Cleaning & Preprocessing text\n",
    "- Remove HTML\n",
    "- Tokenization + Remove punctuation\n",
    "- Remove stopwords\n",
    "- Lemmatization or stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train.Message[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    return BeautifulSoup(text,'lxml').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return \"\".join([c for c in text if c not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    return [w for w in text if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemmatizer(text):\n",
    "    return [lemmatizer.lemmatize(i) for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stemmer(text):\n",
    "    return [stemmer.stem(i) for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train['Message'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ham', 'spam'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train['Category']\n",
    "\n",
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_index = {'ham':0,'spam':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Represent each word in ONE-HOT encoding\n",
    "- as of now, for reducing vector length of input we set min frequency of token to be **SOME INT VALUE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_frequency(l):\n",
    "    count = {}\n",
    "    for tokens in l:\n",
    "        for token in tokens:\n",
    "            if token not in count:\n",
    "                count[token]=1\n",
    "            else:\n",
    "                count[token]+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = token_frequency(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('u', 23),\n",
       " ('call', 21),\n",
       " ('2', 17),\n",
       " ('go', 16),\n",
       " ('free', 16),\n",
       " ('ur', 14),\n",
       " ('mobil', 13),\n",
       " ('text', 12),\n",
       " ('txt', 11),\n",
       " ('claim', 11)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(tf.items(),key=lambda x:x[1],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(tf):\n",
    "    v = {}\n",
    "    v['pad']=0\n",
    "    v['unk']=1\n",
    "    for token in tf:\n",
    "        if tf[token]>=min_freq:\n",
    "            v[token] = len(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocabulary(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's convert tokens to index and make vector for each word in a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['500',\n",
       "  'new',\n",
       "  'mobil',\n",
       "  '2004',\n",
       "  'must',\n",
       "  'go',\n",
       "  'txt',\n",
       "  'nokia',\n",
       "  '89545',\n",
       "  'collect'],\n",
       " 15)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = t[0]\n",
    "tokens[:10],len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [vocab[token] if token in vocab else vocab['unk'] for token in tokens]\n",
    "len(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's convert these indices to one-hot vectors\n",
    "- shape of input will be sequence_length * vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(len(indices),len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[range(len(indices)),indices]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]), torch.Size([15, 749]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation of RNN:\n",
    "\\begin{equation*}\n",
    "h_t = tanh( W_{ih}X_t + b_{ih} + W_{hh}h_{t-1} + b_{hh})\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell = nn.RNNCell(len(vocab),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih torch.Size([100, 749])\n",
      "weight_hh torch.Size([100, 100])\n",
      "bias_ih torch.Size([100])\n",
      "bias_hh torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for name,p in rnn_cell.named_parameters():\n",
    "    print(name,p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    h = rnn_cell(x[i].view(1,-1),h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**value of hidden vector after iterating over all input time steps**\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.1341e-02,  2.8719e-02, -1.0772e-02,  6.0397e-02,  9.1936e-05,\n",
       "         -1.8411e-02,  1.4357e-02, -2.1835e-01,  1.2941e-01, -2.9292e-01,\n",
       "         -1.3177e-01,  1.2926e-03, -4.9819e-03, -2.2580e-01,  8.8884e-03,\n",
       "          3.2912e-02, -1.1327e-01, -5.6633e-02,  1.8505e-01, -9.2389e-02,\n",
       "         -8.8952e-02, -8.9404e-02,  1.3897e-02,  8.5317e-02,  6.4917e-02,\n",
       "         -1.9610e-01, -6.6982e-02, -8.1507e-02, -1.3211e-02,  2.4464e-01,\n",
       "         -2.5653e-01, -6.1257e-02,  2.0731e-01,  2.4796e-01,  9.5485e-02,\n",
       "         -1.2610e-01,  8.1142e-02, -4.1523e-02,  2.9730e-02, -9.0939e-02,\n",
       "         -2.2146e-01, -1.0134e-01,  1.0169e-01,  1.4718e-01, -1.4418e-01,\n",
       "         -3.7013e-02, -5.1221e-02, -9.5732e-02,  4.8320e-03, -7.1987e-02,\n",
       "         -1.8768e-02, -4.5836e-02,  1.2190e-01,  1.1848e-01,  5.8956e-02,\n",
       "          2.0251e-01,  1.9261e-01, -2.2986e-01,  1.2078e-01, -9.9152e-02,\n",
       "         -7.9297e-02,  1.3925e-01, -8.1363e-02,  6.8298e-02, -2.3147e-02,\n",
       "         -3.3784e-01,  9.5200e-02,  6.9125e-02,  9.0649e-02,  6.1417e-02,\n",
       "         -1.6391e-01,  3.0920e-02, -2.2305e-01,  2.2881e-02, -9.7214e-02,\n",
       "         -9.0991e-02, -1.8927e-02, -2.5088e-01, -1.8268e-01,  2.1233e-01,\n",
       "          2.3664e-01, -2.1800e-01,  1.8458e-03,  7.5277e-02,  1.2480e-02,\n",
       "          2.3675e-01,  1.9788e-01, -9.1117e-02,  1.8105e-01,  5.0906e-03,\n",
       "         -4.7417e-02,  7.3079e-02, -8.8698e-02, -2.3613e-01,  2.1137e-01,\n",
       "         -1.1536e-01,  3.2299e-02, -2.7782e-01, -1.9813e-02, -1.2079e-01]],\n",
       "       grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"**value of hidden vector after iterating over all input time steps**\")\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In RNNCell,\n",
    "    \n",
    "    inputs are looped over each time steps\n",
    "\n",
    "<a href=\"https://pytorch.org/docs/stable/nn.html?highlight=rnncell#torch.nn.RNNCell\">PyTorch RNNCell reference</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN for 1 training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(len(vocab),100,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [vocab[token] if token in vocab else vocab['unk'] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(len(indices),len(vocab))\n",
    "\n",
    "x[range(len(indices)),indices]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]), torch.Size([1, 15, 749]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.expand((1,-1,len(vocab)))\n",
    "x,x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shape of h:-**\n",
    "    \n",
    "    h = (num_layers*num_directions, bacth_size, hidden_units)\n",
    "    \n",
    "    where num_layers parameter take int value as inputs which build ups STACKED RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros(1,1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "output,hidden = rnn(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 15, 100]), torch.Size([1, 1, 100]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape,hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**output** - output of all time steps of all batches\n",
    "\n",
    "**hidden** - output of last time step of all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Linear(100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0133, -0.0085]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = classifier(hidden.view(1,100))\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN for m training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([{'params':rnn.parameters()},{'params':classifier.parameters()}],lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6907348036766052\n",
      "0.7733471989631653\n",
      "0.6941800117492676\n",
      "0.6946882605552673\n",
      "0.6787651777267456\n",
      "0.6782664060592651\n",
      "0.6580341458320618\n",
      "0.7723941206932068\n",
      "0.6276066899299622\n",
      "0.6285117864608765\n",
      "0.6459813117980957\n",
      "0.5659758448600769\n",
      "0.770775318145752\n",
      "0.6630669832229614\n",
      "0.7781795263290405\n",
      "0.5748857259750366\n",
      "0.8560469150543213\n",
      "0.7791211009025574\n",
      "0.666670024394989\n",
      "0.6679280996322632\n",
      "0.8450742959976196\n",
      "0.7599931955337524\n",
      "0.6608483791351318\n",
      "0.6080837845802307\n",
      "0.7753790616989136\n",
      "0.6121601462364197\n",
      "0.5934309959411621\n",
      "0.8441199064254761\n",
      "0.6034643054008484\n",
      "0.809683084487915\n",
      "0.6284765601158142\n",
      "0.6458376049995422\n",
      "0.8057158589363098\n",
      "0.5511355400085449\n",
      "0.7776252031326294\n",
      "0.6398602724075317\n",
      "0.7940396070480347\n",
      "0.7654731273651123\n",
      "0.6363545060157776\n",
      "0.6081461906433105\n",
      "0.598836362361908\n",
      "0.6256642937660217\n",
      "0.5477328300476074\n",
      "0.8283072710037231\n",
      "0.5811066627502441\n",
      "0.5175595283508301\n",
      "0.8443266749382019\n",
      "0.5660105347633362\n",
      "0.8884944915771484\n",
      "0.6143222451210022\n",
      "0.5051776766777039\n",
      "0.5066477060317993\n",
      "0.5412478446960449\n",
      "0.5584248900413513\n",
      "0.5079882144927979\n",
      "0.9202408790588379\n",
      "0.5236380100250244\n",
      "0.9483571648597717\n",
      "0.555442214012146\n",
      "0.9882237911224365\n",
      "0.8808908462524414\n",
      "0.8513011336326599\n",
      "0.8887803554534912\n",
      "0.5867530703544617\n",
      "0.8711761236190796\n",
      "0.7914431691169739\n",
      "0.594039261341095\n",
      "0.7569139003753662\n",
      "0.789466381072998\n",
      "0.7548173666000366\n",
      "0.7256181836128235\n",
      "0.6203188896179199\n",
      "0.6973758935928345\n",
      "0.6880097389221191\n",
      "0.6989824175834656\n",
      "0.7215630412101746\n",
      "0.6417533159255981\n",
      "0.7175566554069519\n",
      "0.6669546961784363\n",
      "0.6722308993339539\n",
      "0.7055598497390747\n",
      "0.6113506555557251\n",
      "0.7157619595527649\n",
      "0.7744500637054443\n",
      "0.7288873791694641\n",
      "0.6653486490249634\n",
      "0.8003047704696655\n",
      "0.6693302392959595\n",
      "0.7011497616767883\n",
      "0.7181807160377502\n",
      "0.6593647599220276\n",
      "0.7009695172309875\n",
      "0.6660441160202026\n",
      "0.6541909575462341\n",
      "0.7063271999359131\n",
      "0.601762592792511\n",
      "0.6125575304031372\n",
      "0.7851256728172302\n",
      "0.5998663902282715\n",
      "0.596271276473999\n"
     ]
    }
   ],
   "source": [
    "for doc,y in zip(indices,labels):\n",
    "    x = torch.zeros(len(doc),len(vocab))\n",
    "    x[range(len(doc)),doc]=1\n",
    "    x = x.expand((1,-1,len(vocab)))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    h = torch.zeros(1,1,100)\n",
    "    output,hidden = rnn(x,h)\n",
    "    preds = classifier(hidden.view(1,100))\n",
    "    \n",
    "    loss = crit(preds,torch.LongTensor([labels_index[y]]))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    print(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why loop over each document?**\n",
    "\n",
    "    different documents are of differnt lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch-wise processing\n",
    "\n",
    "**Why do we need padding?**\n",
    "- sequence length of different documents will be of different length\n",
    "- so flow will be as follows:<br>\n",
    "      for doc in documents:\n",
    "          for token in doc:\n",
    "              pass to RNNCell\n",
    "- the above methods has huge complexity\n",
    "- in order to process in batch-wise, we make all documents length to be of same length\n",
    "\n",
    "    \n",
    "    Thus padding comes in, which means pads 0's to documents which has length less than max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths = [len(d) for d in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros(len(indices),max_length,len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 26, 749])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    X[[i],range(len(indices[i])),indices[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.LongTensor([labels_index[i] for i in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(len(vocab),100,batch_first=True)\n",
    "        self.classifier = nn.Linear(100,2)\n",
    "        \n",
    "    def forward(self,x,h):\n",
    "        output,hidden = self.rnn(x,h)\n",
    "        return self.classifier(hidden.view(-1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7059726119041443\n",
      "0.6927284002304077\n",
      "0.687088131904602\n",
      "0.6846276521682739\n",
      "0.7352521419525146\n",
      "0.6896708011627197\n",
      "0.6700661182403564\n",
      "0.7321271300315857\n",
      "0.7024848461151123\n",
      "0.7004063129425049\n",
      "0.6880125403404236\n",
      "0.7133035659790039\n",
      "0.6875213384628296\n",
      "0.6610767841339111\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    for i in range(0,X.shape[0],bs):\n",
    "        xb = X[i:i+bs]\n",
    "        yb = Y[i:i+bs]\n",
    "        h = torch.zeros(1,xb.shape[0],100)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb,h)\n",
    "        loss = crit(preds,yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test['Message'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "TY = torch.LongTensor([labels_index[i] for i in test.Category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for index_num in range(len(test)):\n",
    "\n",
    "    T = torch.zeros(len(indices[index_num]),len(vocab))\n",
    "    T[range(len(indices[index_num])),indices[index_num]]=1\n",
    "    T = T.expand((1,-1,len(vocab)))\n",
    "\n",
    "    h = torch.zeros(1,T.shape[0],100)\n",
    "    with torch.no_grad():\n",
    "        predictions.append(F.softmax(model(T,h)).argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.LongTensor(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy:', tensor(0.5000))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Accuracy:\",(predictions==TY).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Number of positives predicted', tensor(100))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Number of positives predicted\",(predictions==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Number of negatives predicted', tensor(0))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Number of negatives predicted\",(predictions==0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train['Message'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    if len(indices[i])<max_length:\n",
    "        indices[i]+=[0]*(max_length-len(indices[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 26])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.LongTensor(indices)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.LongTensor([labels_index[i] for i in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(len(vocab),200,padding_idx=0)\n",
    "        self.gru = nn.GRU(200,100,batch_first=True)\n",
    "        self.classifier = nn.Linear(100,2)\n",
    "        \n",
    "    def forward(self,x,h):\n",
    "        x = self.emb(x)\n",
    "        output,hidden = self.gru(x,h)\n",
    "        return self.classifier(hidden.view(-1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071463465690613\n",
      "0.6979575753211975\n",
      "0.6886698603630066\n",
      "0.6717616319656372\n",
      "0.7129810452461243\n",
      "0.7022449970245361\n",
      "0.681523323059082\n",
      "0.6616697311401367\n",
      "0.7170751690864563\n",
      "0.7050150632858276\n",
      "0.6769896149635315\n",
      "0.655048131942749\n",
      "0.7197584509849548\n",
      "0.7066013813018799\n",
      "0.6740244030952454\n",
      "0.6506035327911377\n",
      "0.7213941216468811\n",
      "0.707334578037262\n",
      "0.6720314025878906\n",
      "0.6475527882575989\n",
      "0.7222890257835388\n",
      "0.7074819803237915\n",
      "0.670655369758606\n",
      "0.6454074382781982\n",
      "0.7226772308349609\n",
      "0.7072418928146362\n",
      "0.6696776151657104\n",
      "0.6438555717468262\n",
      "0.7227279543876648\n",
      "0.7067539691925049\n",
      "0.6689603328704834\n",
      "0.6426944732666016\n",
      "0.7225596904754639\n",
      "0.7061136960983276\n",
      "0.6684150695800781\n",
      "0.6417908668518066\n",
      "0.7222533822059631\n",
      "0.7053844928741455\n",
      "0.6679835319519043\n",
      "0.6410560011863708\n"
     ]
    }
   ],
   "source": [
    "model = Sentiment()\n",
    "\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "bs=32\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i in range(0,X.shape[0],bs):\n",
    "        xb = X[i:i+bs]\n",
    "        yb = Y[i:i+bs]\n",
    "        h = torch.zeros(1,xb.shape[0],100)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb,h)\n",
    "        loss = crit(preds,yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test['Message'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]\n",
    "\n",
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "TY = torch.LongTensor([labels_index[i] for i in test.Category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for index_num in range(len(test)):\n",
    "    T = torch.LongTensor([indices[index_num]])\n",
    "    h = torch.zeros(1,T.shape[0],100)\n",
    "    with torch.no_grad():\n",
    "        predictions.append(F.softmax(model(T,h)).argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.LongTensor(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5300)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions==TY).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 4, 46, 4)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = ((TY==1)*(predictions==1)).sum().item()\n",
    "\n",
    "tn = ((TY==0)*(predictions==0)).sum().item()\n",
    "\n",
    "fn = ((TY==1)*(predictions==0)).sum().item()\n",
    "\n",
    "fp = ((TY==0)*(predictions==1)).sum().item()\n",
    "tp,tn,fp,tn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postive label - measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5157894736842106\n",
      "Recall: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",tp/(tp+fp))\n",
    "\n",
    "print(\"Recall:\",tp/(tp+fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative label - measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8\n",
      "Recall: 0.08\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",tn/(tn+fn))\n",
    "\n",
    "print(\"Recall:\",tn/(tn+fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.4647e-06, -2.3619e-05,  3.6112e-06,  ..., -6.4651e-06,\n",
       "          3.0508e-05,  3.1949e-05],\n",
       "        [ 3.8217e-06, -1.8697e-06,  2.0537e-08,  ..., -3.3056e-06,\n",
       "          1.6019e-06,  1.4679e-06],\n",
       "        [ 4.7258e-06,  4.9265e-06, -3.7685e-06,  ..., -6.7187e-07,\n",
       "         -1.5365e-05, -1.2797e-05],\n",
       "        ...,\n",
       "        [ 1.3999e-04, -1.1195e-04, -2.9343e-04,  ..., -6.4626e-05,\n",
       "         -4.5285e-04, -2.5619e-04],\n",
       "        [ 4.0799e-04,  3.3392e-04, -1.2833e-04,  ..., -4.9071e-05,\n",
       "         -8.6815e-04, -6.3166e-04],\n",
       "        [-2.0011e-04, -1.0462e-04,  9.6279e-05,  ...,  3.8692e-05,\n",
       "          5.1566e-04,  3.2200e-04]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.gru.weight_hh_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.0679e-07,  1.8996e-06, -1.9252e-07,  ...,  6.4073e-06,\n",
       "         -2.4909e-06,  4.2302e-06],\n",
       "        [ 4.4886e-07, -9.7651e-06,  2.8628e-06,  ...,  2.8889e-06,\n",
       "         -3.6571e-06,  1.9938e-06],\n",
       "        [-4.1288e-06, -9.5711e-07, -3.3210e-07,  ...,  4.4093e-06,\n",
       "         -7.6019e-08,  1.3912e-06],\n",
       "        ...,\n",
       "        [ 4.4807e-05, -1.9162e-04,  1.6100e-04,  ..., -1.8276e-05,\n",
       "         -8.2698e-05,  8.5495e-05],\n",
       "        [-2.9542e-04,  4.1173e-04, -1.1771e-04,  ...,  3.1162e-04,\n",
       "          7.6361e-05, -2.0920e-06],\n",
       "        [ 1.8940e-05,  6.3130e-05, -3.7969e-07,  ..., -7.0040e-05,\n",
       "         -5.8885e-05,  3.4946e-06]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.gru.weight_ih_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
