{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('C:/Users/sappusamy/Documents/SriWK/datasets/IMDB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    137\n",
       "positive    113\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    58\n",
       "positive    42\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = dataset[:100]\n",
    "train.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    79\n",
       "positive    71\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = dataset[100:].reset_index(drop=True)\n",
    "test.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP: Cleaning & Preprocessing text\n",
    "- Remove HTML\n",
    "- Tokenization + Remove punctuation\n",
    "- Remove stopwords\n",
    "- Lemmatization or stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    return BeautifulSoup(text,'lxml').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return \"\".join([c for c in text if c not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    return [w for w in text if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemmatizer(text):\n",
    "    return [lemmatizer.lemmatize(i) for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stemmer(text):\n",
    "    return [stemmer.stem(i) for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train['review'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative', 'positive'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train['sentiment']\n",
    "\n",
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_index = {'negative':0,'positive':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Represent each word in ONE-HOT encoding\n",
    "- as of now, for reducing vector length of input we set min frequency of token to be **SOME INT VALUE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_frequency(l):\n",
    "    count = {}\n",
    "    for tokens in l:\n",
    "        for token in tokens:\n",
    "            if token not in count:\n",
    "                count[token]=1\n",
    "            else:\n",
    "                count[token]+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = token_frequency(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movi', 209),\n",
       " ('film', 156),\n",
       " ('one', 104),\n",
       " ('like', 84),\n",
       " ('see', 59),\n",
       " ('even', 59),\n",
       " ('get', 58),\n",
       " ('good', 56),\n",
       " ('scene', 55),\n",
       " ('go', 54)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(tf.items(),key=lambda x:x[1],reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(tf):\n",
    "    v = {}\n",
    "    v['pad']=0\n",
    "    v['unk']=1\n",
    "    for token in tf:\n",
    "        if tf[token]>=min_freq:\n",
    "            v[token] = len(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocabulary(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1665"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's convert tokens to index and make vector for each word in a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['one',\n",
       "  'review',\n",
       "  'mention',\n",
       "  'watch',\n",
       "  '1',\n",
       "  'oz',\n",
       "  'episod',\n",
       "  'youll',\n",
       "  'hook',\n",
       "  'right'],\n",
       " 168)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = t[0]\n",
    "tokens[:10],len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [vocab[token] if token in vocab else vocab['unk'] for token in tokens]\n",
    "len(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's convert these indices to one-hot vectors\n",
    "- shape of input will be sequence_length * vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(len(indices),len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[range(len(indices)),indices]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]), torch.Size([168, 1665]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation of RNN:\n",
    "\\begin{equation*}\n",
    "h_t = tanh( W_{ih}X_t + b_{ih} + W_{hh}h_{t-1} + b_{hh})\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell = nn.RNNCell(len(vocab),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih torch.Size([100, 1665])\n",
      "weight_hh torch.Size([100, 100])\n",
      "bias_ih torch.Size([100])\n",
      "bias_hh torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for name,p in rnn_cell.named_parameters():\n",
    "    print(name,p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    h = rnn_cell(x[i].view(1,-1),h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**value of hidden vector after iterating over all input time steps**\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0131, -0.0322, -0.1322, -0.0975,  0.0204,  0.1817,  0.0846,  0.0201,\n",
       "         -0.0918,  0.0665,  0.0676, -0.0776, -0.0997,  0.0302, -0.1368,  0.2011,\n",
       "          0.1128, -0.0234,  0.1890,  0.0898,  0.0630, -0.0489, -0.1366,  0.1285,\n",
       "         -0.0894,  0.0062,  0.0213,  0.0666,  0.1108,  0.0107, -0.0342,  0.0358,\n",
       "         -0.1576,  0.1320, -0.0721,  0.2109, -0.0256,  0.0909, -0.0953,  0.2060,\n",
       "         -0.0171,  0.0429, -0.1006, -0.0366, -0.0918,  0.2314,  0.0716,  0.0137,\n",
       "         -0.0338,  0.0475,  0.0308,  0.0188, -0.0686,  0.0243,  0.0420,  0.0932,\n",
       "         -0.0346, -0.0535,  0.1153, -0.1892, -0.0197,  0.1771,  0.0563,  0.1012,\n",
       "          0.1362, -0.2485, -0.1255,  0.0852,  0.0730,  0.0133,  0.2124, -0.1108,\n",
       "          0.0870, -0.2446,  0.1138,  0.1723, -0.0421,  0.0054, -0.0879, -0.0137,\n",
       "         -0.0378,  0.1887, -0.2409,  0.1479,  0.1549,  0.0046, -0.0304, -0.0861,\n",
       "         -0.1304,  0.0440, -0.0577,  0.1125,  0.1231, -0.0426, -0.1980,  0.0276,\n",
       "         -0.1516, -0.2592,  0.0317,  0.0155]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"**value of hidden vector after iterating over all input time steps**\")\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In RNNCell,\n",
    "    \n",
    "    inputs are looped over each time steps\n",
    "\n",
    "<a href=\"https://pytorch.org/docs/stable/nn.html?highlight=rnncell#torch.nn.RNNCell\">PyTorch RNNCell reference</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN for 1 training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(len(vocab),100,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [vocab[token] if token in vocab else vocab['unk'] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(len(indices),len(vocab))\n",
    "\n",
    "x[range(len(indices)),indices]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]), torch.Size([1, 168, 1665]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.expand((1,-1,len(vocab)))\n",
    "x,x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shape of h:-**\n",
    "    \n",
    "    h = (num_layers*num_directions, bacth_size, hidden_units)\n",
    "    \n",
    "    where num_layers parameter take int value as inputs which build ups STACKED RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.zeros(1,1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output,hidden = rnn(x,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 168, 100]), torch.Size([1, 1, 100]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape,hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**output** - output of all time steps of all batches\n",
    "\n",
    "**hidden** - output of last time step of all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Linear(100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1841,  0.1122]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = classifier(hidden.view(1,100))\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN for m training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([{'params':rnn.parameters()},{'params':classifier.parameters()}],lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5559003353118896\n",
      "0.5865741968154907\n",
      "0.5760800242424011\n",
      "0.881472110748291\n",
      "0.5523629188537598\n",
      "0.5476473569869995\n",
      "0.5382099747657776\n",
      "0.8598165512084961\n",
      "0.8195828199386597\n",
      "0.5355939865112305\n",
      "0.8742824792861938\n",
      "0.8003334403038025\n",
      "0.8464121222496033\n",
      "0.8539475202560425\n",
      "0.6447441577911377\n",
      "0.7875109910964966\n",
      "0.6243841648101807\n",
      "0.7863596081733704\n",
      "0.5838578343391418\n",
      "0.741943359375\n",
      "0.6739190220832825\n",
      "0.7623177766799927\n",
      "0.6147756576538086\n",
      "0.7852587699890137\n",
      "0.7390691637992859\n",
      "0.6596775650978088\n",
      "0.6310624480247498\n",
      "0.7847815752029419\n",
      "0.7708404064178467\n",
      "0.6257534623146057\n",
      "0.604915201663971\n",
      "0.6955050230026245\n",
      "0.7397541999816895\n",
      "0.5824265480041504\n",
      "0.7451844811439514\n",
      "0.7188671827316284\n",
      "0.7497631311416626\n",
      "0.7459926605224609\n",
      "0.6593024730682373\n",
      "0.7782583832740784\n",
      "0.7049355506896973\n",
      "0.6471307873725891\n",
      "0.6932894587516785\n",
      "0.6283427476882935\n",
      "0.7973484992980957\n",
      "0.648339569568634\n",
      "0.7162867784500122\n",
      "0.7163512706756592\n",
      "0.7036973237991333\n",
      "0.6895565986633301\n",
      "0.6535287499427795\n",
      "0.7471995949745178\n",
      "0.6481081247329712\n",
      "0.6607642769813538\n",
      "0.658033549785614\n",
      "0.7205267548561096\n",
      "0.68142169713974\n",
      "0.6130020022392273\n",
      "0.7172714471817017\n",
      "0.7234385013580322\n",
      "0.6749143600463867\n",
      "0.7007866501808167\n",
      "0.7594087719917297\n",
      "0.6645940542221069\n",
      "0.6359999179840088\n",
      "0.7718759179115295\n",
      "0.6416587829589844\n",
      "0.6569144129753113\n",
      "0.6504695415496826\n",
      "0.6709479093551636\n",
      "0.6288967728614807\n",
      "0.6007227897644043\n",
      "0.8075738549232483\n",
      "0.7884922027587891\n",
      "0.5569612979888916\n",
      "0.7657296061515808\n",
      "0.7582421898841858\n",
      "0.6555558443069458\n",
      "0.639500081539154\n",
      "0.8401498794555664\n",
      "0.7508708834648132\n",
      "0.7046254873275757\n",
      "0.6759529113769531\n",
      "0.592095673084259\n",
      "0.6322216391563416\n",
      "0.5780259966850281\n",
      "0.5843173265457153\n",
      "0.5651975274085999\n",
      "0.5499853491783142\n",
      "0.4520344138145447\n",
      "0.910953938961029\n",
      "0.5441462993621826\n",
      "0.8410158157348633\n",
      "0.8895854949951172\n",
      "0.5285573601722717\n",
      "0.9055904150009155\n",
      "0.5205897688865662\n",
      "0.5125066041946411\n",
      "0.4942466616630554\n",
      "0.901695191860199\n"
     ]
    }
   ],
   "source": [
    "for doc,y in zip(indices,labels):\n",
    "    x = torch.zeros(len(doc),len(vocab))\n",
    "    x[range(len(doc)),doc]=1\n",
    "    x = x.expand((1,-1,len(vocab)))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    h = torch.zeros(1,1,100)\n",
    "    output,hidden = rnn(x,h)\n",
    "    preds = classifier(hidden.view(1,100))\n",
    "    \n",
    "    loss = crit(preds,torch.LongTensor([labels_index[y]]))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    print(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why loop over each document?**\n",
    "\n",
    "    different documents are of differnt lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch-wise processing\n",
    "\n",
    "**Why do we need padding?**\n",
    "- sequence length of different documents will be of different length\n",
    "- so flow will be as follows:<br>\n",
    "      for doc in documents:\n",
    "          for token in doc:\n",
    "              pass to RNNCell\n",
    "- the above methods has huge complexity\n",
    "- in order to process in batch-wise, we make all documents length to be of same length\n",
    "\n",
    "    \n",
    "    Thus padding comes in, which means pads 0's to documents which has length less than max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths = [len(d) for d in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.zeros(len(indices),max_length,len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 372, 1665])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    X[[i],range(len(indices[i])),indices[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.LongTensor([labels_index[i] for i in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(len(vocab),100,batch_first=True)\n",
    "        self.classifier = nn.Linear(100,2)\n",
    "        \n",
    "    def forward(self,x,h):\n",
    "        output,hidden = self.rnn(x,h)\n",
    "        return self.classifier(hidden.view(-1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.695826530456543\n",
      "0.7030476331710815\n",
      "0.6810666918754578\n",
      "0.6966425776481628\n",
      "0.6778326034545898\n",
      "0.6617869734764099\n",
      "0.6349002718925476\n",
      "0.7104899287223816\n",
      "0.7257965803146362\n",
      "0.6569234132766724\n",
      "0.7050983309745789\n",
      "0.6687477827072144\n",
      "0.6482828855514526\n",
      "0.6187847852706909\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    for i in range(0,X.shape[0],bs):\n",
    "        xb = X[i:i+bs]\n",
    "        yb = Y[i:i+bs]\n",
    "        h = torch.zeros(1,xb.shape[0],100)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb,h)\n",
    "        loss = crit(preds,yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test['review'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "TY = torch.LongTensor([labels_index[i] for i in test.sentiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for index_num in range(len(test)):\n",
    "\n",
    "    T = torch.zeros(len(indices[index_num]),len(vocab))\n",
    "    T[range(len(indices[index_num])),indices[index_num]]=1\n",
    "    T = T.expand((1,-1,len(vocab)))\n",
    "\n",
    "    h = torch.zeros(1,T.shape[0],100)\n",
    "    with torch.no_grad():\n",
    "        predictions.append(F.softmax(model(T,h)).argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.LongTensor(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Accuracy:', tensor(0.5267))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Accuracy:\",(predictions==TY).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Number of positives predicted', tensor(0))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Number of positives predicted\",(predictions==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Number of negatives predicted', tensor(150))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Number of negatives predicted\",(predictions==0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train['review'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    if len(indices[i])<max_length:\n",
    "        indices[i]+=[0]*(max_length-len(indices[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 372])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.LongTensor(indices)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.LongTensor([labels_index[i] for i in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(len(vocab),200,padding_idx=0)\n",
    "        self.gru = nn.GRU(200,100,batch_first=True)\n",
    "        self.classifier = nn.Linear(100,2)\n",
    "        \n",
    "    def forward(self,x,h):\n",
    "        x = self.emb(x)\n",
    "        output,hidden = self.gru(x,h)\n",
    "        return self.classifier(hidden.view(-1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6929085850715637\n",
      "0.7052596807479858\n",
      "0.6900385618209839\n",
      "0.673358142375946\n",
      "0.7026670575141907\n",
      "0.690097987651825\n",
      "0.6701661944389343\n",
      "0.6445623636245728\n",
      "0.7138630747795105\n",
      "0.6829387545585632\n",
      "0.660126805305481\n",
      "0.6280755400657654\n",
      "0.7232805490493774\n",
      "0.6790019273757935\n",
      "0.6548410058021545\n",
      "0.6183191537857056\n",
      "0.7303240299224854\n",
      "0.6763519048690796\n",
      "0.6519342064857483\n",
      "0.6123837232589722\n",
      "0.7352997064590454\n",
      "0.6742353439331055\n",
      "0.6502665877342224\n",
      "0.6086880564689636\n",
      "0.738713264465332\n",
      "0.672376811504364\n",
      "0.64927077293396\n",
      "0.6063395738601685\n",
      "0.7410249710083008\n",
      "0.6706810593605042\n",
      "0.6486548185348511\n",
      "0.60481858253479\n",
      "0.7425869703292847\n",
      "0.6691190004348755\n",
      "0.6482614278793335\n",
      "0.603813886642456\n",
      "0.7436491250991821\n",
      "0.6676802039146423\n",
      "0.6480022072792053\n",
      "0.6031358242034912\n"
     ]
    }
   ],
   "source": [
    "model = Sentiment()\n",
    "\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "bs=32\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i in range(0,X.shape[0],bs):\n",
    "        xb = X[i:i+bs]\n",
    "        yb = Y[i:i+bs]\n",
    "        h = torch.zeros(1,xb.shape[0],100)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb,h)\n",
    "        loss = crit(preds,yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test['review'].apply(remove_html)\n",
    "\n",
    "t = t.apply(remove_punctuation)\n",
    "\n",
    "t = t.apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "t = t.apply(remove_stopwords)\n",
    "\n",
    "t = t.apply(word_lemmatizer)\n",
    "\n",
    "t = t.apply(word_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [[vocab[token] if token in vocab else vocab['unk'] for token in doc] for doc in t]\n",
    "\n",
    "max_length = len(max(t,key=lambda x:len(x)))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "TY = torch.LongTensor([labels_index[i] for i in test.sentiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for index_num in range(len(test)):\n",
    "    T = torch.LongTensor([indices[index_num]])\n",
    "    h = torch.zeros(1,T.shape[0],100)\n",
    "    with torch.no_grad():\n",
    "        predictions.append(F.softmax(model(T,h)).argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.LongTensor(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions==TY).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 74, 5, 70)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = ((TY==1)*(predictions==1)).sum().item()\n",
    "\n",
    "tn = ((TY==0)*(predictions==0)).sum().item()\n",
    "\n",
    "fn = ((TY==1)*(predictions==0)).sum().item()\n",
    "\n",
    "fp = ((TY==0)*(predictions==1)).sum().item()\n",
    "tp,tn,fp,fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postive label - measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.16666666666666666\n",
      "Recall: 0.014084507042253521\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",tp/(tp+fp))\n",
    "\n",
    "print(\"Recall:\",tp/(tp+fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative label - measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5138888888888888\n",
      "Recall: 0.9367088607594937\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",tn/(tn+fn))\n",
    "\n",
    "print(\"Recall:\",tn/(tn+fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2776e-05, -1.0590e-05,  1.2248e-05,  ...,  9.4169e-06,\n",
       "         -1.9101e-05,  1.6297e-05],\n",
       "        [-3.3105e-05, -1.5392e-05,  1.7803e-05,  ...,  1.3688e-05,\n",
       "         -2.7764e-05,  2.3687e-05],\n",
       "        [ 5.3344e-07,  2.4802e-07, -2.8687e-07,  ..., -2.2056e-07,\n",
       "          4.4737e-07, -3.8169e-07],\n",
       "        ...,\n",
       "        [ 1.0818e-03,  5.0300e-04, -5.8179e-04,  ..., -4.4730e-04,\n",
       "          9.0729e-04, -7.7408e-04],\n",
       "        [-2.6151e-04, -1.2159e-04,  1.4063e-04,  ...,  1.0812e-04,\n",
       "         -2.1932e-04,  1.8711e-04],\n",
       "        [-1.0494e-04, -4.8793e-05,  5.6437e-05,  ...,  4.3390e-05,\n",
       "         -8.8013e-05,  7.5090e-05]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.gru.weight_hh_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4217e-25,  4.3960e-24,  2.0416e-25,  ...,  5.4143e-24,\n",
       "         -1.1671e-25, -3.4600e-24],\n",
       "        [ 1.5861e-24, -2.8096e-24, -7.8425e-25,  ..., -4.6890e-24,\n",
       "          1.7778e-24,  3.4771e-24],\n",
       "        [-9.9762e-26, -3.0760e-24,  6.0718e-25,  ..., -3.4793e-24,\n",
       "         -1.3614e-24,  1.0589e-24],\n",
       "        ...,\n",
       "        [-4.4773e-23,  3.1713e-22,  4.0156e-23,  ...,  3.4103e-22,\n",
       "          2.3316e-22, -2.7291e-22],\n",
       "        [ 8.6815e-23, -1.1720e-21, -2.1915e-22,  ..., -1.2557e-21,\n",
       "         -4.2305e-22,  9.4109e-22],\n",
       "        [ 5.0904e-25, -9.0626e-23, -1.0189e-23,  ..., -9.3201e-23,\n",
       "         -2.4840e-23,  5.1593e-23]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.gru.weight_ih_l0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
