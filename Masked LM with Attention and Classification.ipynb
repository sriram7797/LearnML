{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook,tnrange\n",
    "from random import shuffle\n",
    "import time\n",
    "from torch.utils.data import Dataset,DataLoader,RandomSampler,TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/root/sentiment/emotions/input/emotions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/root/sentiment/LM/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 40\n",
    "max_pred = 5\n",
    "min_freq = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.text = data.text.apply(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = {}\n",
    "for doc in data.text:\n",
    "    for token in doc:\n",
    "        try:\n",
    "            word_freq[token]+=1\n",
    "        except:\n",
    "            word_freq[token]=1\n",
    "            \n",
    "w2i={\"[PAD]\":0,\"[MASK]\":1,\"[UNK]\":2}\n",
    "for word,count in word_freq.items():\n",
    "    if count>=min_freq:\n",
    "        w2i[word]=len(w2i)\n",
    "i2w = {i:w for w,i in w2i.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i[\"[PAD]\"],w2i[\"[MASK]\"],w2i[\"[UNK]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.text = data.text.apply(lambda x: [w2i[i] if i in w2i else w2i[\"[UNK]\"] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lm_data(docs):\n",
    "    batch=[]\n",
    "    for doc in docs:\n",
    "        if len(doc)>5:\n",
    "            doc = doc[:max_len]\n",
    "            n_pred = min(max_pred,max(1,int(len(doc)*0.15)))\n",
    "            cand_mask_pos = [i+1 for i,token in enumerate(doc[1:]) if token!=w2i[\"[UNK]\"]]\n",
    "            shuffle(cand_mask_pos)\n",
    "            masked_tokens,masked_pos=[],[]\n",
    "            for pos in cand_mask_pos[:n_pred]:\n",
    "                masked_pos.append(pos)\n",
    "                masked_tokens.append(doc[pos])\n",
    "                doc[pos]=w2i[\"[MASK]\"]\n",
    "            n_pad = max_len - len(doc)\n",
    "            doc.extend([w2i[\"[PAD]\"]]*n_pad)\n",
    "            n_pad = max_pred-n_pred\n",
    "            masked_pos.extend([0]*n_pad)\n",
    "            batch.append([doc,masked_pos,masked_tokens])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelConversion:\n",
    "    def fit_transform(self,x):\n",
    "        self.fit(x)\n",
    "        return self.transform(x)\n",
    "    \n",
    "    def fit_by_list(self,x):\n",
    "        self.labels={}\n",
    "        for l in x:\n",
    "            if l not in self.labels:\n",
    "                self.labels[l]=len(self.labels)\n",
    "        self.inverse_labels = {i:l for l,i in self.labels.items()}\n",
    "    \n",
    "    def fit(self,x):\n",
    "        self.labels={}\n",
    "        for l in x:\n",
    "            if l not in self.labels:\n",
    "                self.labels[l]=len(self.labels)\n",
    "        self.inverse_labels = {i:l for l,i in self.labels.items()}\n",
    "    def transform(self,x): \n",
    "        output=[]\n",
    "        for i,l in enumerate(x):\n",
    "            output.append(self.labels[l])\n",
    "        return output\n",
    "                          \n",
    "    def inverse_transform(self,output):\n",
    "        result=[]\n",
    "        for label in output:\n",
    "            result.append(self.inverse_labels[label])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc=LabelConversion()\n",
    "lc.fit(data.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = lc.transform(data.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(docs,labels):\n",
    "    batch=[]\n",
    "    for doc,label in zip(docs,labels):\n",
    "        doc = doc[:max_len]\n",
    "        n_pad = max_len - len(doc)\n",
    "        doc.extend([w2i[\"[PAD]\"]]*n_pad)\n",
    "        batch.append([doc,label])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,vs,emb_dim,hid_dim):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vs,emb_dim,padding_idx=0)\n",
    "        self.enc = nn.LSTM(emb_dim,hid_dim,batch_first=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.emb(x)\n",
    "        hiddens,(h,c) = self.enc(x)\n",
    "        return hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self,hid_dim):\n",
    "        super().__init__()\n",
    "        self.Wh = nn.Linear(hid_dim,hid_dim,bias=False)\n",
    "        self.W = nn.Linear(hid_dim,1,bias=False)\n",
    "        \n",
    "    def forward(self,hiddens):\n",
    "        x = self.Wh(hiddens)\n",
    "        x = self.W(x)\n",
    "        x = x.softmax(dim=1)\n",
    "        c = x*hiddens\n",
    "        return c,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,hid_dim,vs,enc_weight=None):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.fc = nn.Linear(hid_dim,vs)\n",
    "        \n",
    "    def forward(self,c,masked_pos):\n",
    "        bs,mask_len = masked_pos.size()\n",
    "        masked_index=(masked_pos!=0).view(-1)\n",
    "        masked_pos = masked_pos[:,:,None].expand(-1,-1,self.hid_dim)\n",
    "        output = torch.gather(c,1,masked_pos)\n",
    "        output = output.view(bs*mask_len,-1)[masked_index]\n",
    "        logits = self.fc(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self,encoder,decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self,x,masked_pos):\n",
    "        c,s = self.encoder(x)\n",
    "        logits = self.decoder(c,masked_pos)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self,hid_dim,int_dim,num_classes):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(hid_dim,int_dim)\n",
    "        self.clf = nn.Linear(int_dim,num_classes)\n",
    "        \n",
    "    def forward(self,c):\n",
    "        context = c.sum(1)\n",
    "        hidden = self.layer(context)\n",
    "        logits = self.clf(hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self,encoder,classifier):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def forward(self,x):\n",
    "        c,s = self.encoder(x)\n",
    "        logits = self.classifier(c)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 300\n",
    "vs = len(w2i)\n",
    "num_classes = len(lc.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_encoder = Encoder(vs,emb_dim,emb_dim)\n",
    "lm_attention = Attention(emb_dim)\n",
    "decoder = Decoder(emb_dim,vs,lm_encoder.emb.weight)\n",
    "\n",
    "lm_model = nn.Sequential(lm_encoder,lm_attention)\n",
    "\n",
    "lang_model = LanguageModel(lm_model,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_model.to(device)\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids,masked_positions,targets = list(zip(*get_lm_data(docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMDataset(Dataset):\n",
    "    def __init__(self,token_ids,m_pos,y):\n",
    "        self.x=torch.LongTensor(token_ids)\n",
    "        self.masked_pos=torch.LongTensor(m_pos)\n",
    "        self.y=y\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        return self.x[i],self.masked_pos[i],self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMDataLoader(DataLoader):\n",
    "    def __init__(self,dataset,bs,**kwargs):\n",
    "        super().__init__(dataset,batch_size=bs,**kwargs)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for i in range(0,len(self.dataset),self.batch_size):\n",
    "            yield self.dataset[i:i+self.batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_ds = LMDataset(token_ids,masked_positions,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_sampler = RandomSampler(lm_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_dl = LMDataLoader(lm_ds,bs=bs,sampler=lm_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lang_model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3b4bb21073470bbc2da62940170be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=10, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3089), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 6.216586980340428\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3089), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 5.403260256562978\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3089), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Loss: 5.111074184894331\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3089), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Loss: 4.92146635501794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3089), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Loss: 4.762309688243205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3089), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Loss: 4.620094018723997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3089), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Loss: 4.487770601862929\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3089), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Loss: 4.361287543380702\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3089), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Loss: 4.240156300983761\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3089), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Loss: 4.124820207000221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tnrange(epochs,desc=\"Epochs\"):\n",
    "    e_loss = 0\n",
    "    itr = 0\n",
    "    t = tqdm_notebook(lm_dl,leave=False,total=len(lm_dl))\n",
    "    for xb,masked_pos,yb in t:\n",
    "        yb = torch.cat([torch.tensor(i) for i in yb])\n",
    "        if device=='cuda':\n",
    "            xb = xb.cuda()\n",
    "            masked_pos= masked_pos.cuda()\n",
    "            yb = yb.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        logits=lang_model(xb,masked_pos)\n",
    "        loss = loss_fn(logits,yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t.set_postfix(loss=loss.item())\n",
    "        e_loss+=(loss.item()*len(xb))\n",
    "        itr+=len(xb)\n",
    "    print(\"Epoch: {} Loss: {}\".format(epoch+1,e_loss/itr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Attention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(lang_model,path+\"lm_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/root/sentiment/LM/w2i.pkl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lc,save_path + \"label_obj.pkl\")\n",
    "joblib.dump(w2i,save_path + \"w2i.pkl\")\n",
    "joblib.dump(i2w,save_path + \"w2i.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids,targets = zip(*get_class_data(docs,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(token_ids,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassDataset(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = torch.LongTensor(x)\n",
    "        self.y = torch.LongTensor(y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        return self.x[i],self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ClassDataset(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler=RandomSampler(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds,batch_size=bs,sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vs,emb_dim,emb_dim)\n",
    "attention = Attention(emb_dim)\n",
    "classifier = Classifier(emb_dim,emb_dim,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(encoder,attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(lm_model.state_dict(),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model = ClassificationModel(model,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model.to(device)\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(clf_model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c1e951168d4ef7aa814b885d71ed11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=5, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2443), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.08747265762774693\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2443), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Loss: 0.08509520569857858\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2443), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Loss: 0.08421211934886262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2443), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Loss: 0.0828182890452193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2443), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Loss: 0.08173147901538087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tnrange(epochs,desc=\"Epochs\"):\n",
    "    e_loss = 0\n",
    "    itr = 0\n",
    "    t = tqdm_notebook(dl,leave=False,total=len(dl))\n",
    "    for xb,yb in t:\n",
    "        if device=='cuda':\n",
    "            xb = xb.cuda()\n",
    "            yb = yb.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        logits=clf_model(xb)\n",
    "        loss = loss_fn(logits,yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t.set_postfix(loss=loss.item())\n",
    "        e_loss+=loss.item()*len(xb)\n",
    "        itr+=len(xb)\n",
    "    print(\"Epoch: {} Loss: {}\".format(epoch+1,e_loss/itr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ClassDataset(xtest,ytest)\n",
    "test_dl = DataLoader(test_ds,batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=815), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = tqdm_notebook(test_dl,leave=False,total=len(test_dl))\n",
    "preds=[]\n",
    "actual=[]\n",
    "with torch.no_grad():\n",
    "    for xb,yb in t:\n",
    "        if device=='cuda':\n",
    "            xb = xb.cuda()\n",
    "            yb = yb.cuda()\n",
    "        logits=clf_model(xb)\n",
    "        preds.append(logits.cpu())\n",
    "        actual.append(yb.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat(preds)\n",
    "actual = torch.cat(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = preds.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadness\n",
      "Precision: 0.9811513684856334\n",
      "Recall: 0.9567905338030978\n",
      "*****\n",
      "joy\n",
      "Precision: 0.9742959119402538\n",
      "Recall: 0.9171607657123496\n",
      "*****\n",
      "love\n",
      "Precision: 0.7679495624353063\n",
      "Recall: 0.9429231658001156\n",
      "*****\n",
      "anger\n",
      "Precision: 0.9143064633260711\n",
      "Recall: 0.9616025552006666\n",
      "*****\n",
      "fear\n",
      "Precision: 0.8845809236784231\n",
      "Recall: 0.906813627254509\n",
      "*****\n",
      "surprise\n",
      "Precision: 0.8027073732718893\n",
      "Recall: 0.7602291325695582\n",
      "*****\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(lc.labels)):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "    for i,j in zip(yhat,actual):\n",
    "        if i==k and j==k:\n",
    "            tp+=1\n",
    "        if i!=k and j==k:\n",
    "            fn+=1\n",
    "        if i==k and j!=k:\n",
    "            fp+=1\n",
    "        if i!=k and j!=k:\n",
    "            tn+=1\n",
    "    try:\n",
    "        p = tp/(tp+fp)\n",
    "    except:\n",
    "        p = 0\n",
    "    try:\n",
    "        r = tp/(tp+fn)\n",
    "    except:\n",
    "        r = 0\n",
    "    print(lc.inverse_labels[k])\n",
    "    print(\"Precision: {}\\nRecall: {}\\n*****\".format(p,r))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ClassificationModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Attention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Classifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(clf_model,path+\"clf_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
